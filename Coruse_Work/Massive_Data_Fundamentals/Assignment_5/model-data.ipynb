{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Predictive Model(s)\n",
    "\n",
    "In this workbook, you will read the merged dataset you created previously and you will create pipelines to build a binary classification model to predict wether a trip has a tip or not.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Read in your merged dataset\n",
    "2. Use transformes and encoders to perform feature engineering\n",
    "3. Split into training and testing\n",
    "4. Build `LogisticRegression` model(s) and train them using pipelines\n",
    "5. Evaluate the performance of the model(s) using `BinaryClassificationMetrics`\n",
    "\n",
    "You are welcome to add as many cells as you need below up until the next section. **You must include comments in your code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"lab-ml\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = spark.read\\\n",
    "  .format('parquet')\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('s3://gu-502-course/trip_fare_combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+---+\n",
      "|           medallion|        hack_license|vendor_id|rate_code|store_and_fwd_flag|    pickup_datetime|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|payment_type|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|total_amount|tip|\n",
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+---+\n",
      "|6F910ABF764B97720...|205994280475874B5...|      VTS|        1|              null|2013-04-20 20:23:00|2013-04-20 20:30:00|              6|            420.0|         1.13|       -73.99228|      40.719482|        -74.00296|       40.728542|         CRD|       11.5|      1.0|    0.5|       1.3|         0.0|        14.3|  1|\n",
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+------------+-----------+---------+-------+----------+------------+------------+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_data = df_data.randomSplit([0.8, 0.20], seed=24)\n",
    "train_data = splitted_data[0]\n",
    "test_data = splitted_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler, Imputer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringIndexer_label = StringIndexer(inputCol=\"tip\", outputCol=\"label\", handleInvalid='skip')\n",
    "stringIndexer_payment_type = StringIndexer(inputCol=\"payment_type\",\n",
    "                                           outputCol=\"payment_type_IX\", handleInvalid='skip')\n",
    "stringIndexer_saff = StringIndexer(inputCol=\"store_and_fwd_flag\",\n",
    "                                   outputCol=\"store_and_fwd_flag_IX\", handleInvalid='skip')\n",
    "encoder1 = OneHotEncoder(inputCol=\"store_and_fwd_flag_IX\", outputCol=\"store_and_fwd_flag_vec\")\n",
    "encoder2 = OneHotEncoder(inputCol=\"payment_type_IX\", outputCol=\"payment_type_vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=['passenger_count', 'rate_code', \n",
    "              'fare_amount', 'trip_distance', 'store_and_fwd_flag_IX', 'payment_type_IX'],\n",
    "    outputCol='features', handleInvalid='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol='label', featuresCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to convert label indexes back into the actual labels.  \n",
    "labelConverter = IndexToString(inputCol='prediction', outputCol='predictedLabel',\n",
    "                             labels=stringIndexer_label.fit(df_data).labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(stages=[stringIndexer_label, stringIndexer_payment_type, stringIndexer_saff,\n",
    "                               encoder1, encoder2, vectorAssembler_features, lr, labelConverter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = pipeline_lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model_lr.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol='label', rawPredictionCol='prediction',\n",
    "                                         metricName='areaUnderROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following cells, please provide the requested code and output. Do not change the order and/or structure of the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, print the Area Under the Curve (AUC) for your binary classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9815434407576723"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = evaluator.evaluate(predictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, provide the code that saves your model your S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr.save(\"s3://gu-502-course/trip_fare_model\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
